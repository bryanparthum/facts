{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97d87bf2-bda2-4051-8561-d25f1049403b",
   "metadata": {},
   "source": [
    "# RCT-FACTS on EIS\n",
    "This notebook:\n",
    "* Introduces RADICAL-Cybertools as a tool for enabling large-scale science on HPC machines.\n",
    "* How to use RADICAL-Cybertools in building FACTS pipelines using different approaches. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RADICAL Cybertools (RCT):\n",
    "RADICAL-Cybertools is an abstractions-based suite of well-defined capabilities that are architected for scalable, interoperable and sustainable approaches to support science on a range of high-performance and distributed computing systems.\n",
    "\n",
    "There are three main components (i.e., building blocks):\n",
    "* RADICAL-SAGA: a standards-based interface that provides basic interoperability across a range of computing middleware; \n",
    "* RADICAL-Pilot: a scalable and flexible pilot-based runtime system that provides flexible application-level resource management capabilities;\n",
    "* RADICAL-EnTK: simplifies the ability to implement ensemble-based applications.\n",
    "\n",
    "RCT Supports heterogeneous workloads and resources: \n",
    "* Single/multi cores/GPUs/nodes,\n",
    "* MPI/OpenMP tasks;\n",
    "* Executable and function tasks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RADICAL-EnTK (Ensemble Toolkit):\n",
    "EnTK promotes ensembles to a high-level programming abstraction, providing specific interfaces and execution models for ensemble-based applications via PST model:\n",
    "\n",
    "* (P) Pipeline -sequence of stages;\n",
    "* (S) Stage\t - set of tasks;\n",
    "* (T) Task\t - self-contained process.\n",
    "\n",
    "Workflow management components compose a special purpose management system, which manages resources and task execution via a runtime system (general purpose)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How To Install RCT:\n",
    "\n",
    "RCT is available to install via both `pip` and `conda`. In this demo, we will learn how to install via `pip` and use [RCT tools](https://radical-cybertools.github.io/) .\n",
    "\n",
    "Below, we will check, install, and run RCT locally on this machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52349ceb-7dd7-4cd3-bb34-6ca5db1ac0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_rct = !radical-stack\n",
    "if 'radical.entk' in ' '.join(check_rct):\n",
    "    print('RCT tools are installed')\n",
    "else:\n",
    "    rct_tools = ['saga', 'gtod', 'pilot', 'entk']\n",
    "    for tool in rct_tools:\n",
    "        print(f'Installing radical.{tool} is in progress')\n",
    "        cmd_out = !pip install radical.{tool}\n",
    "    print('Done')\n",
    "\n",
    "!radical-stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FACTS\n",
    "The Framework for Assessing Changes To Sea-level (FACTS) is an open-source modular, scalable, and extensive framework for global mean, regional, and extreme sea level projection that is designed to support the characterization of ambiguity in sea-level projections. It is designed so users can easily explore deep uncertainty by investigating the implications on GMSL, RSL, and ESL of different choices for different processes. Its modularity allows components to be represented by either simple or complex model. Because it is built upon the Radical-PILOT computing stack, different modules can be dispatched for execution on resources appropriate to their computational complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6331f5-a532-4e13-a8c3-74ab12dfb8ab",
   "metadata": {},
   "source": [
    "Run FACTS modules using EnTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9281e055-af1a-4f11-8e60-e220411577d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not use animated output in notebooks\n",
    "os.environ['RADICAL_LOG_LVL'] ='DEBUG'\n",
    "os.environ['RADICAL_REPORT_ANIME'] = 'False'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ddc3a8-bd13-4399-98a4-2a310fee3b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "facts_dir = os.path.dirname(os.path.dirname(current_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Below is a demonstration of how to use EnTK API to express and run FACTS pipelines interactively:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf9c8a4-9945-416e-a082-1bdda0475a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from radical.entk import Pipeline, Stage, Task, AppManager\n",
    "\n",
    "task_path = f'{facts_dir}/modules/fair/temperature'\n",
    "#task_env_cmd = os.path.expanduser('~') + '/ve/facts_eis_demo/bin/activate'\n",
    "task_env_cmd = os.path.expanduser('~') + '/fve/bin/activate'\n",
    "\n",
    "def generate_fair_temp_pipeline(pipeline_id):\n",
    "    # Create a Pipeline object\n",
    "    p = Pipeline()\n",
    "\n",
    "    # Create A single stage for Preporcessing and Fitting tasks\n",
    "    # as these tasks can run concurrently with no dependencies\n",
    "    s0 = Stage()\n",
    "    t0 = Task()\n",
    "    t0.name = 'fair.preprocessing'\n",
    "    t0.cpu_reqs = {'cpu_processes':1}\n",
    "    t0.pre_exec = [f'. {task_env_cmd}']\n",
    "    t0.executable = f'python {task_path}/fair_temperature_preprocess.py --pipeline_id {pipeline_id}'\n",
    "    t0.upload_input_data = [f'{task_path}/rcmip/rcmip-emissions-annual-means-v5-1-0.csv']\n",
    "\n",
    "    t1 = Task()\n",
    "    t1.name = 'fair.fitting'\n",
    "    t1.cpu_reqs = {'cpu_processes':1}\n",
    "    t1.pre_exec = [f'. {task_env_cmd}']\n",
    "    t1.executable = f'python {task_path}/fair_temperature_fit.py --pipeline_id {pipeline_id}'\n",
    "    t1.upload_input_data = [f'{task_path}/parameters/fair_ar6_climate_params_v4.0.nc']\n",
    "    s0.add_tasks([t0, t1])\n",
    "\n",
    "    # Create A seprate Projecting Stage which runs after stage 0 outputs are produced\n",
    "    s1 = Stage()\n",
    "    t2 = Task()\n",
    "    t2.name = 'fair.projectting'\n",
    "    t2.cpu_reqs = {'cpu_processes':1}\n",
    "    t2.pre_exec = [f'. {task_env_cmd}']\n",
    "    t2.executable = f'python {task_path}/fair_temperature_project.py --pipeline_id {pipeline_id}'\n",
    "    t2.upload_input_data = [f'{task_path}/{pipeline_id}_preprocess.pkl',\n",
    "                            f'{task_path}/{pipeline_id}_fit.pkl']\n",
    "\n",
    "    t2.download_output_data = ['0_climate.nc', '0_gsat.nc', '0_ohc.nc', '0_oceantemp.nc']\n",
    "    s1.add_tasks(t2)\n",
    "\n",
    "    # Create Projecting Stage\n",
    "    s2 = Stage()\n",
    "    t3 = Task()\n",
    "    t3.name = 'fair.postprocessing'\n",
    "    t3.cpu_reqs = {'cpu_processes':1}\n",
    "    t3.pre_exec = [f'. {task_env_cmd}']\n",
    "    t3.executable = f'python {task_path}/fair_temperature_postprocess.py --pipeline_id {pipeline_id}'\n",
    "    s2.add_tasks(t3)\n",
    "\n",
    "    p.add_stages([s0, s1, s2])\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We create a list of pipelines that we want to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b36006-1639-499b-9cca-eb8f9b83f8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = []\n",
    "for i in range(1):\n",
    "    pipe = generate_fair_temp_pipeline(pipeline_id=i)\n",
    "    pipelines.append(pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the required resources for all pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa4e6c4-70ab-4a02-8a6b-c986ee371202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Application Manager\n",
    "appman = AppManager()\n",
    "\n",
    "# Create a dictionary describe four mandatory keys:\n",
    "# resource, walltime, and cpus\n",
    "# resource is 'local.localhost' to execute locally\n",
    "res_dict = {'resource': 'local.localhost', 'walltime': 30, 'cpus': 8,}\n",
    "# Assign resource request description to the Application Manager\n",
    "appman.resource_desc = res_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run the pipelines on the local machine (EIS VM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c91236-177c-45ab-879e-8874ceeaec49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the workflow as a set or list of Pipelines to the Application Manager\n",
    "# Note: The list order is not guaranteed to be preserved\n",
    "appman.workflow = pipelines\n",
    "# Run the Application Manager\n",
    "appman.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell above displays the output generated by running a FACTS Fair pipeline using `Radical.EnTk`.\n",
    "\n",
    "When EnTK resolves the task dependencies, it is handed over to the `Radical.Pilot` runtime system. In this phase, the task goes through the following states: `SCHEDULED`, `SUBMITTED`, and eventually, `EXECUTED`. These transitions occur on the designated computing resources; in this case, we used the `localhost` (i.e., the current virtual machine itself).\n",
    "\n",
    "Once all tasks are executed, EnTK initiates the termination process for the allocated computing resources. EnTK collects and compiles the necessary performance profiles and logs from the executed tasks as part of this finalization step.\n",
    "\n",
    "Finally, it gracefully closes the session, ensuring that all resources are released and the experiment is completed in an orderly manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similar to running RCT-FACTS interactively, we can run RCT-FACTS as a Python executable:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the facts.demo experiment through the command line for FittedISMIP to using the output of Fair/Temperature above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd {facts_dir} && python3 {facts_dir}/runFACTS.py {facts_dir}/experiments/facts.demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8ed5d7-84c7-4fd3-b297-3dc52598e2cb",
   "metadata": {},
   "source": [
    "# Plotting the FittedISMIP GrIS Module Results\n",
    "The code below takes the temperature projection data outputted through FAIR and plots the surafce temperature against the global mean seal level rise projection from the FittedISMIP GrIS (greenland icesheet) module. It then pulls the quantile information from the GMSL data for comparison to AR6 FACTS projections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e55c91-4e66-4b39-898b-c3fafa213cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2100 # Default year was 2150\n",
    "module = 'GrIS'\n",
    "module_set = 'FittedISMIP'\n",
    "sheet = 'GIS'\n",
    "print(os.getcwd())\n",
    "\n",
    "# load fair temperation gsat data and projection data\n",
    "fair_temp = f'0_gsat.nc'\n",
    "module_data = f'../../experiments/facts.demo/output/facts.demo.GrIS1f.FittedISMIP.GrIS_GIS_globalsl.nc'\n",
    "\n",
    "# Open .nc data sets and restrict to specific year\n",
    "x_585 = (xr.open_dataset(fair_temp).squeeze(drop = True).surface_temperature.sel(years = year, drop = True)).values\n",
    "y_585 = (xr.open_dataset(module_data).squeeze(drop = True).sea_level_change.sel(years = year, drop = True)/10).values\n",
    "quantile_spp585 = np.quantile(y_585,[.05,.17,.5,.83,.95])\n",
    "\n",
    "plt.title(f'{module_set}/{module} - {sheet}')\n",
    "plt.xlabel('FAIR GSAT')\n",
    "plt.ylabel(f'{module_set.capitalize()}/{module} [cm]')\n",
    "\n",
    "# Plot Data\n",
    "plt.scatter(x_585, y_585, s=3, label=f'ssp585: {quantile_spp585}',color='blue')\n",
    "plt.legend(loc=\"upper left\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
