{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97d87bf2-bda2-4051-8561-d25f1049403b",
   "metadata": {},
   "source": [
    "# RCT-FACTS on EIS\n",
    "This notebook will check, install and run [RCT tools](https://radical-cybertools.github.io/) and [FACTS](https://fact-sealevel.readthedocs.io/en/latest/index.html) locally on this machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff4fe4a-2925-4c31-b98f-49461ceea0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068afe3e-0dea-4eff-912e-e57f1e867855",
   "metadata": {},
   "source": [
    "Check if RCT tools are installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52349ceb-7dd7-4cd3-bb34-6ca5db1ac0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_rct = !radical-stack\n",
    "if 'radical.entk' in ' '.join(check_rct):\n",
    "    print('RCT tools are installed')\n",
    "else:\n",
    "    rct_tools = ['saga', 'gtod', 'pilot', 'entk']\n",
    "    for tool in rct_tools:\n",
    "        print(f'Installing radical.{tool} is in progress')\n",
    "        cmd_out = !pip install radical.{tool}\n",
    "    print('Done')\n",
    "\n",
    "!radical-stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6331f5-a532-4e13-a8c3-74ab12dfb8ab",
   "metadata": {},
   "source": [
    "Run FACTS dummy experiments using RCT tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9281e055-af1a-4f11-8e60-e220411577d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not use animated output in notebooks\n",
    "os.environ['RADICAL_LOG_LVL'] ='DEBUG'\n",
    "os.environ['RADICAL_REPORT_ANIME'] = 'False'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ddc3a8-bd13-4399-98a4-2a310fee3b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "facts_dir = os.path.dirname(os.path.dirname(current_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf9c8a4-9945-416e-a082-1bdda0475a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from radical.entk import Pipeline, Stage, Task, AppManager\n",
    "\n",
    "task_path = f'{facts_dir}/modules/fair/temperature'\n",
    "task_env_cmd = os.path.expanduser('~') + '/ve/facts_eis_demo/bin/activate'\n",
    "\n",
    "def generate_fair_temp_pipeline(pipeline_id):\n",
    "    # Create a Pipeline object\n",
    "    p = Pipeline()\n",
    "\n",
    "    # Create A single stage for Preporcessing and Fitting tasks\n",
    "    # as these tasks can run concurrently with no dependencies\n",
    "    s0 = Stage()\n",
    "    t0 = Task()\n",
    "    t0.name = 'fair.preprocessing'\n",
    "    t0.cpu_reqs = {'cpu_processes':1}\n",
    "    t0.pre_exec = [f'. {task_env_cmd}']\n",
    "    t0.executable = f'python {task_path}/fair_temperature_preprocess.py --pipeline_id {pipeline_id}'\n",
    "    t0.upload_input_data = [f'{task_path}/rcmip/rcmip-emissions-annual-means-v5-1-0.csv']\n",
    "\n",
    "    t1 = Task()\n",
    "    t1.name = 'fair.fitting'\n",
    "    t1.cpu_reqs = {'cpu_processes':1}\n",
    "    t1.pre_exec = [f'. {task_env_cmd}']\n",
    "    t1.executable = f'python {task_path}/fair_temperature_fit.py --pipeline_id {pipeline_id}'\n",
    "    t1.upload_input_data = [f'{task_path}/parameters/fair_ar6_climate_params_v4.0.nc']\n",
    "    s0.add_tasks([t0, t1])\n",
    "\n",
    "    # Create A seprate Projecting Stage which runs after stage 0 outputs are produced\n",
    "    s1 = Stage()\n",
    "    t2 = Task()\n",
    "    t2.name = 'fair.projectting'\n",
    "    t2.cpu_reqs = {'cpu_processes':1}\n",
    "    t2.pre_exec = [f'. {task_env_cmd}']\n",
    "    t2.executable = f'python {task_path}/fair_temperature_project.py --pipeline_id {pipeline_id}'\n",
    "    t2.upload_input_data = [f'{task_path}/{pipeline_id}_preprocess.pkl',\n",
    "                            f'{task_path}/{pipeline_id}_fit.pkl']\n",
    "\n",
    "    t2.download_output_data = ['0_climate.nc', '0_gsat.nc', '0_ohc.nc', '0_oceantemp.nc']\n",
    "    s1.add_tasks(t2)\n",
    "\n",
    "    # Create Projecting Stage\n",
    "    s2 = Stage()\n",
    "    t3 = Task()\n",
    "    t3.name = 'fair.postprocessing'\n",
    "    t3.cpu_reqs = {'cpu_processes':1}\n",
    "    t3.pre_exec = [f'. {task_env_cmd}']\n",
    "    t3.executable = f'python {task_path}/fair_temperature_postprocess.py --pipeline_id {pipeline_id}'\n",
    "    s2.add_tasks(t3)\n",
    "\n",
    "    p.add_stages([s0, s1, s2])\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b36006-1639-499b-9cca-eb8f9b83f8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = []\n",
    "for i in range(1):\n",
    "    pipe = generate_fair_temp_pipeline(pipeline_id=i)\n",
    "    pipelines.append(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa4e6c4-70ab-4a02-8a6b-c986ee371202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Application Manager\n",
    "appman = AppManager()\n",
    "\n",
    "# Create a dictionary describe four mandatory keys:\n",
    "# resource, walltime, and cpus\n",
    "# resource is 'local.localhost' to execute locally\n",
    "res_dict = {'resource': 'local.localhost', 'walltime': 30, 'cpus': 8,}\n",
    "# Assign resource request description to the Application Manager\n",
    "appman.resource_desc = res_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c91236-177c-45ab-879e-8874ceeaec49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the workflow as a set or list of Pipelines to the Application Manager\n",
    "# Note: The list order is not guaranteed to be preserved\n",
    "appman.workflow = pipelines\n",
    "# Run the Application Manager\n",
    "appman.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8ed5d7-84c7-4fd3-b297-3dc52598e2cb",
   "metadata": {},
   "source": [
    "# Plotting the FittedISMIP GrIS Module results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e55c91-4e66-4b39-898b-c3fafa213cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2100 # Default year was 2150\n",
    "module = 'GrIS'\n",
    "module_set = 'FittedISMIP'\n",
    "sheet = 'GIS'\n",
    "\n",
    "# load fair temperation gsat data and projection data\n",
    "fair_temp = f'{current_dir}/0_gsat.nc'\n",
    "module_data = f'{current_dir}/0_oceantemp.nc'\n",
    "\n",
    "# Open .nc data sets and restrict to specific year\n",
    "x_585 = (xr.open_dataset(fair_temp).squeeze(drop = True).surface_temperature.sel(years = year, drop = True)).values\n",
    "y_585 = (xr.open_dataset(module_data).squeeze(drop = True).sea_level_change.sel(years = year, drop = True)/10).values\n",
    "quantile_spp585 = np.quantile(y_585,[.05,.17,.5,.83,.95])\n",
    "\n",
    "plt.title(f'{module_set}/{module} - {sheet}')\n",
    "plt.xlabel('FAIR GSAT')\n",
    "plt.ylabel(f'{module_set.capitalize()}/{module} [cm]')\n",
    "\n",
    "# Plot Data\n",
    "plt.scatter(x_585, y_585, s=3, label=f'ssp585: {quantile_spp585}',color='blue')\n",
    "plt.legend(loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d03af89",
   "metadata": {},
   "source": [
    "The cell above displays the output generated by running a sample pipeline experiment using `Radical.entk` for the FACTS workflow. This pipeline consists of a single stage containing a single task named `preprocess.task1`.\n",
    "\n",
    "When the task dependencies are resolved by EnTK, it is then handed over to the `Radical.pilot` runtime system. In this phase, the task goes through the following states: `SCHEDULED`, `SUBMITTED`, and eventually, `EXECUTED`. These transitions occur on the designated computing resources and in this case we used the `localhost` (i.e. the current virtual machine itself).\n",
    "\n",
    "Once all of the tasks are executed, EnTK initiates the termination process for the allocated computing resources. As part of this finalization step, EnTK collects and compiles the necessary performance profiles and logs from the executed tasks.\n",
    "\n",
    "Finally, it gracefully closes the session, ensuring that all resources are released, and the experiment is completed in an orderly manner."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
